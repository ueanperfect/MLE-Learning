旷视一二面连着：牛客视频面，每面一个小时，只记得下面这些
1、BN 计算过程，训练和测试的区别，训练是线性的吗？测试可以和卷积融合到一起
2、softmax公式，如果乘上一个a>1， 则概率分布怎么变？变得陡峭，
3、讲一下双边滤波，了解其他滤波吗？什么滤波可以保留边缘信息？
4、撕题 剑指offer原题 
5、手写梯度下降、反向传播？不会写，换成手写NMS
6、目标跟踪用的什么网络？（SiamRPN++），讲一下
7、anchorbase和anchorfree区别，anchorfree的实现方式
8、BN和其他的（如ln）的区别？是否线性？
9、网络训练过程中有哪些可以调的东西

旷视三面：
集群怎么实现的，docker相关 linux权限相关
kmeans 怎么做的
联合双边滤波 
除了联合双边滤波还有什么方法优化边缘
手写BN
撕题：j>=i, 求 max a[j]-a[i] 要求O(n) 复杂度

旷视技术终面：
范浩强老师面的，大佬就是大佬，人很好，我紧张坏了，面完下来手还在抖
简单介绍一个项目
python写统计一个文件夹下所有文件，如果我想跳过软连接呢？
pytorch 写双线性插值

(旷视HR小姐姐真的好好，范浩强老师也真的好棒，又帅又有才，写错代码也态度也特别好的指出我的错误，要不是我自己觉得自己太菜了不敢去旷视我肯定选旷视，从面试到选offer体验极好，推荐大家去)
